{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ivn/Documents/PhD/Transformer Research/Code/Benchmarking\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "if str(current_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(current_dir))\n",
    "\n",
    "print(current_dir)\n",
    "\n",
    "from src import (\n",
    "    DataConfig, DataLoader, ModelingStrategy, ReleaseManager, BenchmarkPipeline, create_config\n",
    ")\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = DataConfig(\n",
    "    mapping_path = 'data/feature_mapping_train.pkl',\n",
    "    features_path = \"/Users/ivn/Documents/PhD/Transformer Research/Code/Benchmarking/data/db_snapshot_offsite/train_data/processed/train_data_features.feather\",\n",
    "    target_path = \"/Users/ivn/Documents/PhD/Transformer Research/Code/Benchmarking/data/db_snapshot_offsite/train_data/train_data/train_data_target.feather\",\n",
    "    split_date=\"2016-01-01\",\n",
    ")\n",
    "\n",
    "sku_tuples=[(1912, 7), (377, 1), (715, 7)]\n",
    "\n",
    "quantiles = [0.5, 0.7, 0.9, 0.95, 0.99]\n",
    "pipeline = BenchmarkPipeline(data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(data_config)\n",
    "data = loader.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipeline = BenchmarkPipeline(data_config)\n",
    "\n",
    "# Step 1: Tune hyperparameters\n",
    "tune_result = pipeline.run_experiment(\n",
    "    sku_tuples=10,\n",
    "    modeling_strategy=ModelingStrategy.COMBINED,\n",
    "    model_type=\"xgboost_quantile\",\n",
    "    quantile_alphas=[0.7],\n",
    "    mode=\"hp_tune\",\n",
    "    tune_on=50,\n",
    "    tuning_config={'n_trials': 100, 'n_folds': 5}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  7.27it/s]\n",
      "Training models: 100%|██████████| 3/3 [00:01<00:00,  2.12it/s]\n"
     ]
    }
   ],
   "source": [
    "results_lightning_std = pipeline.run_experiment(\n",
    "    sku_tuples=sku_tuples,\n",
    "    modeling_strategy=ModelingStrategy.INDIVIDUAL,\n",
    "    model_type=\"xgboost_quantile\",\n",
    "    quantile_alphas=quantiles,\n",
    "    hyperparameters = {\n",
    "        \"eta\": 0.05,\n",
    "        \"max_depth\": 8,\n",
    "        \"min_child_weight\": 20,\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 0.7,\n",
    "        \"gamma\": 1.0,   \n",
    "        \"lambda\": 10.0,\n",
    "        \"alpha\": 1.0,\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"num_boost_round\": 100,\n",
    "        \"seed\": 42\n",
    "},\n",
    "    experiment_name=\"xgb_quantile_test\",\n",
    "    evaluate_on_test=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model type: xgboost_quantile\n",
      "Strategy: individual\n",
      "SKU tuples: [(715, 7)]\n",
      "Quantile level: 0.5\n",
      "quantile_score: [0.  0.  0.  0.5 1.  0.5 0.  0.5 0.5 1.  0.  0.5 0.5 0.  1.  0.5 0.5 0.5\n",
      " 0.  0.  1.  0.  0.  0.  1.  0.5 1.  0.5 0.  0.5 0.5 0.5 0.5 1.  0.5 1.5\n",
      " 0.  0.5 0.  0.5 1.5 0.5 4.  0.5 0.  0.5 0.  1.  0.5 0.  0.5 0.5 1.5 0.\n",
      " 0.5 0.5 0.5 0.5 2.  0.5 0.5 0.5 0.5 0.5 1.  0.  0.5 0.5 1.  0.5 1.5 0.5\n",
      " 0.  0.5 0.5 0.5 0.  0.5 2.  0.  0.5 0.5 0.5 0.5 0.  0.  1.  0.  0.  0.5\n",
      " 0.5 0.  0.5 0.  0.  0.5 1.  0.5 0.5 0.  1.  0.5 0.5 0.5 0.5 1.  1.  0.\n",
      " 0.5 0.  0.  0.  0.  0.  0.5 0.5 0.  0.  0.  0.  0.  0.  0.5 0.  0.  0.5\n",
      " 0.5 1.  0.  0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.  1.  0.5 0.  0.  0.  1.5]\n",
      "predictions: [1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      "overall stats: ----------------------------------------------------\n",
      "number of models trained: 15\n"
     ]
    }
   ],
   "source": [
    "sample_result = results_lightning_std.training_results[10]\n",
    "print(f\"Model type: {sample_result.model_type}\")\n",
    "print(f\"Strategy: {sample_result.modeling_strategy.value}\")\n",
    "print(f\"SKU tuples: {sample_result.sku_tuples}\")\n",
    "print(f\"Quantile level: {sample_result.quantile_level}\")\n",
    "print(f\"quantile_score: {sample_result.performance_metrics.get('quantile_score', 'N/A')}\")\n",
    "print(f\"predictions: {sample_result.performance_metrics.get('predictions', 'N/A')}\")\n",
    "print(\"overall stats: ----------------------------------------------------\")\n",
    "print(f\"number of models trained: {len(results_lightning_std.training_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quantile_score': array([0. , 0. , 0. , 0.5, 1. , 0.5, 0. , 0.5, 0.5, 1. , 0. , 0.5, 0.5,\n",
       "        0. , 1. , 0.5, 0.5, 0.5, 0. , 0. , 1. , 0. , 0. , 0. , 1. , 0.5,\n",
       "        1. , 0.5, 0. , 0.5, 0.5, 0.5, 0.5, 1. , 0.5, 1.5, 0. , 0.5, 0. ,\n",
       "        0.5, 1.5, 0.5, 4. , 0.5, 0. , 0.5, 0. , 1. , 0.5, 0. , 0.5, 0.5,\n",
       "        1.5, 0. , 0.5, 0.5, 0.5, 0.5, 2. , 0.5, 0.5, 0.5, 0.5, 0.5, 1. ,\n",
       "        0. , 0.5, 0.5, 1. , 0.5, 1.5, 0.5, 0. , 0.5, 0.5, 0.5, 0. , 0.5,\n",
       "        2. , 0. , 0.5, 0.5, 0.5, 0.5, 0. , 0. , 1. , 0. , 0. , 0.5, 0.5,\n",
       "        0. , 0.5, 0. , 0. , 0.5, 1. , 0.5, 0.5, 0. , 1. , 0.5, 0.5, 0.5,\n",
       "        0.5, 1. , 1. , 0. , 0.5, 0. , 0. , 0. , 0. , 0. , 0.5, 0.5, 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0.5, 0. , 0. , 0.5, 0.5, 1. , 0. , 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0. , 1. , 0.5, 0. , 0. , 0. , 1.5]),\n",
       " 'predictions': array([1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1.,\n",
       "        1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "        0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
       "        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "        0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "        0., 0., 1., 0., 0., 0., 0.], dtype=float32)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_result.performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_result.performance_metrics.get('quantile_score').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.46853146853146854)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_result.performance_metrics.get('quantile_score').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quantile_score': array([0. , 0. , 0. , 0.5, 1. , 0.5, 0. , 0.5, 0.5, 1. , 0. , 0.5, 0.5,\n",
       "        0. , 1. , 0.5, 0.5, 0.5, 0. , 0. , 1. , 0. , 0. , 0. , 1. , 0.5,\n",
       "        1. , 0.5, 0. , 0.5, 0.5, 0.5, 0.5, 1. , 0.5, 1.5, 0. , 0.5, 0. ,\n",
       "        0.5, 1.5, 0.5, 4. , 0.5, 0. , 0.5, 0. , 1. , 0.5, 0. , 0.5, 0.5,\n",
       "        1.5, 0. , 0.5, 0.5, 0.5, 0.5, 2. , 0.5, 0.5, 0.5, 0.5, 0.5, 1. ,\n",
       "        0. , 0.5, 0.5, 1. , 0.5, 1.5, 0.5, 0. , 0.5, 0.5, 0.5, 0. , 0.5,\n",
       "        2. , 0. , 0.5, 0.5, 0.5, 0.5, 0. , 0. , 1. , 0. , 0. , 0.5, 0.5,\n",
       "        0. , 0.5, 0. , 0. , 0.5, 1. , 0.5, 0.5, 0. , 1. , 0.5, 0.5, 0.5,\n",
       "        0.5, 1. , 1. , 0. , 0.5, 0. , 0. , 0. , 0. , 0. , 0.5, 0.5, 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0.5, 0. , 0. , 0.5, 0.5, 1. , 0. , 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0. , 1. , 0.5, 0. , 0. , 0. , 1.5]),\n",
       " 'predictions': array([1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1.,\n",
       "        1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "        0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
       "        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "        0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "        0., 0., 1., 0., 0., 0., 0.], dtype=float32)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_result.performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_manager = ReleaseManager()\n",
    "output_dir = Path(\"./xgb_releases_2\")\n",
    "release_path = release_manager.create_complete_release(\n",
    "    experiment_results=results_lightning_std,  # Your ExperimentResults from pipeline\n",
    "    base_output_dir=output_dir\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Data in piepeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sku = (715, 7)\n",
    "loader = DataLoader(data_config)\n",
    "loader.load_data(lazy=False)\n",
    "dataset = loader.prepare_modeling_dataset([sku], ModelingStrategy.INDIVIDUAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(data_config)\n",
    "# Don't call load_data() at all - let prepare_modeling_dataset do it\n",
    "dataset = loader.prepare_modeling_dataset([sku], ModelingStrategy.INDIVIDUAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access data\n",
    "X_train_pipeline = dataset.X_train\n",
    "y_train_pipeline = dataset.y_train\n",
    "X_test_pipeline = dataset.X_test\n",
    "y_test_pipeline = dataset.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(741, 132)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pipeline.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check data in prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data loading\n",
    "mapping_path = \"/Users/ivn/Documents/PhD/Transformer Research/Code/Benchmarking/data/feature_mapping_train.pkl\"\n",
    "features_path = \"/Users/ivn/Documents/PhD/Transformer Research/Code/Benchmarking/data/db_snapshot_offsite/train_data/processed/train_data_features.feather\"\n",
    "target_path = \"/Users/ivn/Documents/PhD/Transformer Research/Code/Benchmarking/data/db_snapshot_offsite/train_data/train_data/train_data_target.feather\"\n",
    "\n",
    "with open(mapping_path, 'rb') as f:\n",
    "    mapping = pickle.load(f)\n",
    "\n",
    "train_features = pl.read_ipc(features_path)\n",
    "train_target = pl.read_ipc(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (train_features\n",
    "     .lazy()\n",
    "     .filter(pl.col('productID') == 715)\n",
    "     .filter(pl.col('storeID') == 7)\n",
    "     .drop_nulls()\n",
    "     .sort(\"date\",\"skuID\")\n",
    "     .collect())\n",
    "\n",
    "X_bdIDs = (X\n",
    "           .lazy()\n",
    "           .select('bdID')\n",
    "           .unique()\n",
    "           .collect()\n",
    "           .to_numpy()\n",
    "           .flatten())\n",
    "\n",
    "y = (train_target\n",
    "     .lazy()\n",
    "     .filter(pl.col(\"bdID\").is_in(X_bdIDs))\n",
    "     .join(\n",
    "         X.lazy().select(\"bdID\",\"skuID\"), \n",
    "         on=\"bdID\", \n",
    "         how=\"left\")\n",
    "     .sort(\"date\",\"skuID\")\n",
    "     .collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date = pl.date(2016, 1, 1)\n",
    "X_train = X.filter(pl.col(\"date\") < split_date)\n",
    "X_test = X.filter(pl.col(\"date\") >= split_date)\n",
    "y_train = y.filter(pl.col(\"date\") < split_date)\n",
    "y_test = y.filter(pl.col(\"date\") >= split_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cols = ['frequency',\n",
    " 'idx',\n",
    " 'bdID',\n",
    " 'base_date',\n",
    " 'date',\n",
    " 'dateID',\n",
    " 'skuID',\n",
    " 'productID',\n",
    " 'storeID',\n",
    " 'companyID',\n",
    " 'is_daily',\n",
    " 'missing_value',\n",
    " 'not_for_sale',\n",
    " 'name',\n",
    " 'name-2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly set dtype to float64 for all arrays\n",
    "X_train = (X_train\n",
    "            .sort(\"date\",\"skuID\")\n",
    "            .select(pl.selectors.exclude(meta_cols)))\n",
    "\n",
    "y_train = (y_train\n",
    "            .sort(\"date\",\"skuID\")\n",
    "            .select(\"target\")\n",
    "            .to_numpy())  # Also flatten to ensure 1D\n",
    "\n",
    "X_test = (X_test\n",
    "        .sort(\"date\",\"skuID\")\n",
    "        .select(pl.selectors.exclude(meta_cols)))\n",
    "\n",
    "y_test = (y_test\n",
    "        .sort(\"date\",\"skuID\")\n",
    "        .select(\"target\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape test:    True\n",
      "Train label shape test:  True\n",
      "------------------------------\n",
      "Test set shape test:   True\n",
      "Test label shape test: True\n"
     ]
    }
   ],
   "source": [
    "#wrap them into print statements to see the output\n",
    "print(\"Train set shape test:   \", X_train.shape == X_train_pipeline.shape )\n",
    "print(\"Train label shape test: \", y_train.shape == y_train_pipeline.shape )\n",
    "print(30*\"-\")\n",
    "print(\"Test set shape test:  \", X_test.shape == X_test_pipeline.shape )\n",
    "print(\"Test label shape test:\", y_test.shape == y_test_pipeline.shape ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set check:     True\n",
      "Training label check:   True\n",
      "------------------------------\n",
      "Test set check:    True\n",
      "Test label check:  True\n"
     ]
    }
   ],
   "source": [
    "#test if prototype and pipeline data are the same\n",
    "print(\"Training set check:    \", (X_train == X_train_pipeline).to_numpy().all())\n",
    "print(\"Training label check:  \",(y_train == y_train_pipeline).all())\n",
    "print(30*\"-\")\n",
    "print(\"Test set check:   \", (X_test == X_test_pipeline).to_numpy().all())\n",
    "print(\"Test label check: \",(y_test == y_test).to_numpy().all())  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Benchmarking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
